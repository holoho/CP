{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN4PqDt3oZPUaALzG1ez5Ju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/holoho/CP/blob/main/cp2_project_car_color.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_RBe-XFisxN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI/CP2/cartrain"
      ],
      "metadata": {
        "id": "jmMKMNh3i5Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/cartrain/red.zip\" -d  \"/content/drive/MyDrive/AI/CP2/cartrain/red\"\n",
        "!unzip -O cp949 \"/content/drive/MyDrive/AI/CP2/cartrain/black.zip\" -d  \"/content/drive/MyDrive/AI/CP2/cartrain/black\"\n",
        "!unzip -O cp949 \"/content/drive/MyDrive/AI/CP2/cartrain/blue.zip\" -d  \"/content/drive/MyDrive/AI/CP2/cartrain/blue\"\n",
        "!unzip -O cp949 \"/content/drive/MyDrive/AI/CP2/cartrain/grey.zip\" -d  \"/content/drive/MyDrive/AI/CP2/cartrain/grey\"\n",
        "!unzip -O cp949 \"/content/drive/MyDrive/AI/CP2/cartrain/white.zip\" -d  \"/content/drive/MyDrive/AI/CP2/cartrain/white\""
      ],
      "metadata": {
        "id": "SOxiaoxsjTXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI/CP2/carvalid\n",
        "!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/carvalid/red.zip\" -d  \"/content/drive/MyDrive/AI/CP2/carvalid/red\"\n",
        "!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/carvalid/black.zip\" -d  \"/content/drive/MyDrive/AI/CP2/carvalid/black\"\n",
        "!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/carvalid/blue.zip\" -d  \"/content/drive/MyDrive/AI/CP2/carvalid/blue\"\n",
        "!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/carvalid/grey.zip\" -d  \"/content/drive/MyDrive/AI/CP2/carvalid/grey\"\n",
        "!unzip -qq -O cp949 \"/content/drive/MyDrive/AI/CP2/carvalid/white.zip\" -d  \"/content/drive/MyDrive/AI/CP2/carvalid/white\""
      ],
      "metadata": {
        "id": "Z1AHgJRRj-RA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.style.use('ggplot')"
      ],
      "metadata": {
        "id": "i8A7spb43naK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/AI/CP2/cartrain/'\n",
        "VALID_DIR = '/content/drive/MyDrive/AI/CP2/carvalid/'\n",
        "IMAGE_SIZE = 224 # 이미지 크기 조정\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 4 \n",
        "# computation device\n",
        "device = ('cuda' if torch.cuda.is_available() else 'gpu')\n",
        "print(f\"Computation device: {device}\\n\")"
      ],
      "metadata": {
        "id": "m14I-eWa_Hti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train transform\n",
        "def get_train_transform(IMAGE_SIZE):\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomAdjustSharpness(sharpness_factor=2, p=0.5),\n",
        "        #transforms.RandomGrayscale(p=0.5),\n",
        "        transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
        "        transforms.RandomPosterize(bits=2, p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "    ])\n",
        "    return train_transform\n",
        "\n",
        "# Validation transforms\n",
        "def get_valid_transform(IMAGE_SIZE):\n",
        "    valid_transform = transforms.Compose([\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225]\n",
        "            )\n",
        "    ])\n",
        "    return valid_transform"
      ],
      "metadata": {
        "id": "MRm5-tLs_JrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_datasets():\n",
        "\n",
        "    dataset_train = datasets.ImageFolder(\n",
        "        TRAIN_DIR, \n",
        "        transform=(get_train_transform(IMAGE_SIZE))\n",
        "    )\n",
        "    dataset_valid = datasets.ImageFolder(\n",
        "        VALID_DIR, \n",
        "        transform=(get_valid_transform(IMAGE_SIZE))\n",
        "    )\n",
        "    return dataset_train, dataset_valid, dataset_train.classes\n",
        "\n",
        "def get_data_loaders(dataset_train, dataset_valid):\n",
        "    \"\"\"\n",
        "    Prepares the training and validation data loaders.\n",
        "    :param dataset_train: The training dataset.\n",
        "    :param dataset_valid: The validation dataset.\n",
        "    Returns the training and validation data loaders.\n",
        "    \"\"\"\n",
        "    train_loader = DataLoader(\n",
        "        dataset_train, batch_size=BATCH_SIZE, \n",
        "        shuffle=True, num_workers=NUM_WORKERS\n",
        "    )\n",
        "    valid_loader = DataLoader(\n",
        "        dataset_valid, batch_size=BATCH_SIZE, \n",
        "        shuffle=False, num_workers=NUM_WORKERS\n",
        "    )\n",
        "    return train_loader, valid_loader "
      ],
      "metadata": {
        "id": "BlATItMQ_9pC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def build_model(pretrained=True, fine_tune=True, num_classes=5):\n",
        "    if pretrained:\n",
        "        print('[INFO]: Loading pre-trained weights')\n",
        "    else:\n",
        "        print('[INFO]: Not loading pre-trained weights')\n",
        "    model = models.efficientnet_b0(pretrained=pretrained)\n",
        "   \n",
        "\n",
        "    if fine_tune:\n",
        "        print('[INFO]: Fine-tuning all layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = True\n",
        "    elif not fine_tune:\n",
        "        print('[INFO]: Freezing hidden layers...')\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = False\n",
        "\n",
        "    # 마지막 분류 변경\n",
        "    model.classifier[1] = nn.Linear(in_features=1280, out_features=num_classes)\n",
        "    return model"
      ],
      "metadata": {
        "id": "dPmTvDj3ANOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "05qccIWMAetZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, trainloader, optimizer, criterion):\n",
        "    model.train()\n",
        "    print('Training')\n",
        "    train_running_loss = 0.0\n",
        "    train_running_correct = 0\n",
        "    counter = 0\n",
        "    for i, data in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "        counter += 1\n",
        "        image, labels = data\n",
        "        image = image.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass.\n",
        "        outputs = model(image)\n",
        "        # Calculate the loss.\n",
        "        loss = criterion(outputs, labels)\n",
        "        train_running_loss += loss.item()\n",
        "        # Calculate the accuracy.\n",
        "        _, preds = torch.max(outputs.data, 1)\n",
        "        train_running_correct += (preds == labels).sum().item()\n",
        "        # Backpropagation.\n",
        "        loss.backward()\n",
        "        # Update the weights.\n",
        "        optimizer.step()\n",
        "    \n",
        "    # Loss and accuracy for the complete epoch.\n",
        "    epoch_loss = train_running_loss / counter\n",
        "    epoch_acc = 100. * (train_running_correct / len(trainloader.dataset))\n",
        "    return epoch_loss, epoch_acc"
      ],
      "metadata": {
        "id": "zlIn2M2FAznC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation function.\n",
        "def validate(model, testloader, criterion, class_names):\n",
        "    model.eval()\n",
        "    print('Validation')\n",
        "    valid_running_loss = 0.0\n",
        "    valid_running_correct = 0\n",
        "    counter = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in tqdm(enumerate(testloader), total=len(testloader)):\n",
        "            counter += 1\n",
        "            \n",
        "            image, labels = data\n",
        "            image = image.to(device)\n",
        "            labels = labels.to(device)\n",
        "            # Forward pass.\n",
        "            outputs = model(image)\n",
        "            # Calculate the loss.\n",
        "            loss = criterion(outputs, labels)\n",
        "            valid_running_loss += loss.item()\n",
        "            # Calculate the accuracy.\n",
        "            _, preds = torch.max(outputs.data, 1)\n",
        "            valid_running_correct += (preds == labels).sum().item()\n",
        "        \n",
        "    # Loss and accuracy for the complete epoch.\n",
        "    epoch_loss = valid_running_loss / counter\n",
        "    epoch_acc = 100. * (valid_running_correct / len(testloader.dataset))\n",
        "    return epoch_loss, epoch_acc\n"
      ],
      "metadata": {
        "id": "0fTgeAjzA2kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(epochs, model, optimizer, criterion):\n",
        "\n",
        "    torch.save({\n",
        "                'epoch': epochs,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, f\"/content/drive/MyDrive/AI/CP2/model.pth\")\n",
        "\n",
        "def save_plots(train_acc, valid_acc, train_loss, valid_loss):\n",
        "    # Accuracy plots.\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_acc, color='red', linestyle='-', \n",
        "        label='train accuracy'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_acc, color='blue', linestyle='-', \n",
        "        label='validataion accuracy'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/AI/CP2/accuracy.png\")\n",
        "    \n",
        "    # Loss plots.\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.plot(\n",
        "        train_loss, color='orange', linestyle='-', \n",
        "        label='train loss'\n",
        "    )\n",
        "    plt.plot(\n",
        "        valid_loss, color='green', linestyle='-', \n",
        "        label='validataion loss'\n",
        "    )\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig(f\"/content/drive/MyDrive/AI/CP2/loss.png\")\n",
        "plt.style.use('ggplot')\n",
        "class SaveBestModel:\n",
        "\n",
        "    def __init__(\n",
        "        self, best_valid_loss=float('inf')\n",
        "    ):\n",
        "        self.best_valid_loss = best_valid_loss\n",
        "        \n",
        "    def __call__(\n",
        "        self, current_valid_loss, \n",
        "        epoch, model, optimizer, criterion\n",
        "    ):\n",
        "        if current_valid_loss < self.best_valid_loss:\n",
        "            self.best_valid_loss = current_valid_loss\n",
        "            print(f\"\\nBest validation loss: {self.best_valid_loss}\")\n",
        "            print(f\"\\nSaving best model for epoch: {epoch+1}\\n\")\n",
        "            torch.save({\n",
        "                'epoch': epoch+1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': criterion,\n",
        "                }, '/content/drive/MyDrive/AI/CP2/best_model.pth')"
      ],
      "metadata": {
        "id": "eGXxwKCMBEHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train, dataset_valid, dataset_classes = get_datasets()\n",
        "print(f\"[INFO]: Number of training images: {len(dataset_train)}\")\n",
        "print(f\"[INFO]: Number of validation images: {len(dataset_valid)}\")\n",
        "\n",
        "train_loader, valid_loader = get_data_loaders(dataset_train, dataset_valid)"
      ],
      "metadata": {
        "id": "CPWOph2oB-zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_classes"
      ],
      "metadata": {
        "id": "3KhE-HXBCKvx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "rsq5EHHMFqFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.001\n",
        "epochs = 50 \n",
        "device = ('cuda' if torch.cuda.is_available() else 'gpu')\n",
        "print(f\"Computation device: {device}\")\n",
        "print(f\"Learning rate: {lr}\")\n",
        "print(f\"Epochs to train for: {epochs}\\n\")\n",
        "\n",
        "\n",
        "model = build_model(\n",
        "    pretrained=True,\n",
        "    fine_tune=True, \n",
        "    num_classes=len(dataset_classes)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")\n",
        "\n",
        "# Optimizer.\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "# Loss function.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 초기화\n",
        "save_best_model = SaveBestModel()\n",
        "\n",
        "# list for tracking\n",
        "train_loss, valid_loss = [], []\n",
        "train_acc, valid_acc = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"[INFO]: Epoch {epoch+1} of {epochs}\")\n",
        "    train_epoch_loss, train_epoch_acc = train(model, train_loader, \n",
        "                                            optimizer, criterion)\n",
        "    valid_epoch_loss, valid_epoch_acc = validate(model, valid_loader,  \n",
        "                                                criterion, dataset_classes)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    valid_loss.append(valid_epoch_loss)\n",
        "    train_acc.append(train_epoch_acc)\n",
        "    valid_acc.append(valid_epoch_acc)\n",
        "    print(f\"Training loss: {train_epoch_loss:.3f}, training acc: {train_epoch_acc:.3f}\")\n",
        "    print(f\"Validation loss: {valid_epoch_loss:.3f}, validation acc: {valid_epoch_acc:.3f}\")\n",
        "    # 현 epoch에서 도달하는 최소의 손실의 최적화 모델 찾기\n",
        "    save_best_model(\n",
        "          valid_epoch_loss, epoch, model, optimizer, criterion\n",
        "          )\n",
        "\n",
        "    print('-'*50)\n",
        "    time.sleep(2)\n",
        "\n",
        "\n",
        "save_model(epochs, model, optimizer, criterion)\n",
        "\n",
        "save_plots(train_acc, valid_acc, train_loss, valid_loss)\n",
        "print('TRAINING COMPLETE')"
      ],
      "metadata": {
        "id": "Ypv00n5DCPcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "model = build_model(\n",
        "    pretrained=True,\n",
        "    fine_tune=True, \n",
        "    num_classes=len(dataset_classes)\n",
        ").to(device)\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/AI/CP2/best_model.pth')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for inputs, labels in valid_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        output = model(inputs) # Feed Network\n",
        "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
        "        y_pred.extend(output) # Save Prediction\n",
        "        \n",
        "        labels = labels.data.cpu().numpy()\n",
        "        y_true.extend(labels) # Save Truth\n",
        "\n",
        "\n",
        "classes = ('black', 'blue', 'white', 'grey', 'red')\n",
        "\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_pred)\n",
        "df_cm = pd.DataFrame(cf_matrix/np.sum(cf_matrix) *10, index = [i for i in classes],\n",
        "                     columns = [i for i in classes])\n",
        "plt.figure(figsize = (12,7))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('output.png')"
      ],
      "metadata": {
        "id": "Hz44JjxzHbPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}